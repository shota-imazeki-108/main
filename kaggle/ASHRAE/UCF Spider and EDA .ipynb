{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASHRAE - Great Energy Predictor III\n",
    "### refer from...\n",
    "- https://www.kaggle.com/gunesevitan/ashrae-ucf-spider-and-eda-full-test-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site 0 Shape = (3336742, 16)\n",
      "Site 0 Memory Usage = 229.12 MB\n",
      "Site 0 Buildings with Electricity Meter = 105\n",
      "Site 0 Buildings with Chilled Water Meter = 24\n"
     ]
    }
   ],
   "source": [
    "path_data = \"../../input/\"\n",
    "\n",
    "# building_metadata.csv\n",
    "BUILDINGMETADATA_DTYPES = {'site_id': np.uint8, 'building_id': np.uint16, 'square_feet': np.int32, 'year_built': np.float32, 'floor_count': np.float32}\n",
    "df_building_metadata = pd.read_csv(os.path.join(path_data, 'building_metadata.csv'), dtype=BUILDINGMETADATA_DTYPES)\n",
    "\n",
    "# weather_train.csv and weather_test.csv\n",
    "WEATHER_DTYPES = {'site_id': np.uint8, 'air_temperature': np.float32, 'cloud_coverage': np.float32, 'dew_temperature': np.float32, \n",
    "                  'precip_depth_1_hr': np.float32, 'sea_level_pressure': np.float32, 'wind_direction': np.float32, 'wind_speed': np.float32}\n",
    "df_weather_train = pd.read_csv(os.path.join(path_data, 'weather_train.csv'), dtype=WEATHER_DTYPES)\n",
    "df_weather_test = pd.read_csv(os.path.join(path_data, 'weather_test.csv'), dtype=WEATHER_DTYPES)\n",
    "df_weather = pd.concat([df_weather_train, df_weather_test], ignore_index=True)\n",
    "\n",
    "# train.csv\n",
    "TRAIN_DTYPES = {'building_id': np.uint16, 'meter': np.uint8, 'meter_reading': np.float32}\n",
    "df_train = pd.read_csv(os.path.join(path_data, 'train.csv'), dtype=TRAIN_DTYPES)\n",
    "\n",
    "# test.csv\n",
    "TEST_DTYPES = {'building_id': np.uint16, 'meter': np.uint8}\n",
    "df_test = pd.read_csv(os.path.join(path_data, 'test.csv'), dtype=TEST_DTYPES)\n",
    "df_test.drop(columns=['row_id'], inplace=True)\n",
    "    \n",
    "# Keeping site 0\n",
    "df_train = df_train[df_train['building_id'] < 105]\n",
    "df_test = df_test[df_test['building_id'] < 105]\n",
    "df_site0 = pd.concat([df_train, df_test], ignore_index=True, sort=False)\n",
    "\n",
    "for df in [df_site0, df_weather]:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], infer_datetime_format=True)\n",
    "\n",
    "df_site0 = df_site0.merge(df_building_metadata, on='building_id', how='left')\n",
    "df_site0 = df_site0.merge(df_weather, on=['site_id', 'timestamp'], how='left')\n",
    "\n",
    "del df_train, df_test, df_weather_train, df_weather_test, df_weather\n",
    "gc.collect()\n",
    "\n",
    "print('Site 0 Shape = {}'.format(df_site0.shape))\n",
    "print('Site 0 Memory Usage = {:.2f} MB'.format(df_site0.memory_usage().sum() / 1024**2))\n",
    "print('Site 0 Buildings with Electricity Meter = {}'.format(len(df_site0[df_site0['meter'] == 0]['building_id'].unique())))\n",
    "print('Site 0 Buildings with Chilled Water Meter = {}'.format(len(df_site0[df_site0['meter'] == 1]['building_id'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SITE_0_START_URL = 'https://www.oeis.ucf.edu/buildings'\n",
    "SITE_0_AREAS = df_site0['square_feet'].unique()\n",
    "\n",
    "buildings = BeautifulSoup(requests.get(SITE_0_START_URL).text, 'html.parser')\n",
    "\n",
    "building_names = [link.text.strip() for link in buildings.select('table#buildings tr th a')]\n",
    "building_links = [link.get('href') for link in buildings.select('table#buildings tr th a')]\n",
    "building_types = [link.text.strip() for link in buildings.select('table#buildings tr td:nth-child(3)')]\n",
    "building_areas = [link.text.strip() for link in buildings.select('table#buildings tr td:nth-child(4)')]\n",
    "building_euis = [link.text.strip() for link in buildings.select('table#buildings tr td:nth-child(5)')]\n",
    "building_leeds = [link.text.strip() for link in buildings.select('table#buildings tr td:nth-child(6)')]\n",
    "\n",
    "site0_building_metadata = {k: v  for k, v in enumerate(zip(building_names, building_links, building_types, building_areas, building_euis, building_leeds))}\n",
    "df_site0_building_metadata = pd.DataFrame(site0_building_metadata).T.replace('', np.nan)\n",
    "df_site0_building_metadata.columns = ['building_name', 'building_link', 'building_type', 'square_feet', 'eui', 'leed']\n",
    "df_site0_building_metadata['building_url_code'] = df_site0_building_metadata['building_link'].str.split('/', expand=True)[4] # Going to use this while sending AJAX requests\n",
    "df_site0_building_metadata['square_feet'] = df_site0_building_metadata['square_feet'].astype(np.uint32)\n",
    "df_site0_building_metadata['eui'] = df_site0_building_metadata['eui'].astype(np.float32)\n",
    "df_site0_building_metadata = df_site0_building_metadata[df_site0_building_metadata['square_feet'].isin(SITE_0_AREAS)] # square_feet values don't exist in competition data are excluded\n",
    "\n",
    "del building_names, building_links, building_types, building_areas, building_euis, building_leeds, site0_building_metadata, SITE_0_AREAS\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [22:56<00:00,  9.87s/it]\n"
     ]
    }
   ],
   "source": [
    "SITE_0_AJAX_URL = 'https://www.oeis.ucf.edu/getData'\n",
    "BUILDING_URL_CODES = df_site0_building_metadata['building_url_code'].unique().tolist()\n",
    "PARAMS = {\n",
    "    'building': None,\n",
    "    'start-date': '01/01/2016',\n",
    "    'end-date': '01/01/2019',\n",
    "    'resolution': 'hour',\n",
    "    'filetype': 'json'    \n",
    "}\n",
    "\n",
    "df_site0_labels = pd.DataFrame(columns=['meter', 'meter_reading', 'timestamp', 'building_url_code'])\n",
    "\n",
    "for building_url_code in tqdm(BUILDING_URL_CODES):\n",
    "    PARAMS['building'] = building_url_code\n",
    "    building_readings = json.loads(requests.post(url=SITE_0_AJAX_URL, params=PARAMS).text) \n",
    "\n",
    "    for meter_type in building_readings:\n",
    "        \n",
    "        if meter_type['key'] == 'Gas' or meter_type['key'] == 'Irrigation' or meter_type['key'] == 'Water':\n",
    "            continue\n",
    "        \n",
    "        timestamps = pd.Series([value['timestamp'] for value in meter_type['values']])\n",
    "        meter_readings = pd.Series([value['reading'] for value in meter_type['values']])\n",
    "        meter_types = pd.Series(np.tile(meter_type['key'], len(timestamps)))\n",
    "        building_url_codes = pd.Series(np.tile(building_url_code, len(timestamps)))\n",
    "\n",
    "        df_meter_reading = pd.DataFrame(columns=['meter', 'meter_reading', 'timestamp', 'building_url_code'])\n",
    "        df_meter_reading['timestamp'] = timestamps\n",
    "        df_meter_reading['meter_reading'] = meter_readings\n",
    "        df_meter_reading['meter'] = meter_types\n",
    "        df_meter_reading['building_url_code'] = building_url_codes\n",
    "\n",
    "        df_site0_labels = pd.concat([df_site0_labels, df_meter_reading], ignore_index=True)\n",
    "        \n",
    "df_site0_labels = df_site0_labels[df_site0_labels['timestamp'] < '2019-01-01 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique square_feet values in site 0\n",
    "site0_unique_areas = df_site0_building_metadata['square_feet'].value_counts()[df_site0_building_metadata['square_feet'].value_counts() < 2].index.tolist()\n",
    "df_site0_unique_areas = df_building_metadata[df_building_metadata['square_feet'].isin(site0_unique_areas) & (df_building_metadata['site_id'] == 0)]\n",
    "area_building_id_mapping = df_site0_unique_areas.set_index('square_feet')['building_id'].to_dict()\n",
    "df_site0_building_metadata['building_id'] = df_site0_building_metadata['square_feet'].map(area_building_id_mapping)\n",
    "\n",
    "# Not Unique square_feet values in site 0\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"86\"').index, 'building_id'] = '27'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"149\"').index, 'building_id'] = '90'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"12\"').index, 'building_id'] = '33'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"92\"').index, 'building_id'] = '61'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"68\"').index, 'building_id'] = '49'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"142\"').index, 'building_id'] = '67'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"131\"').index, 'building_id'] = '77'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"7\"').index, 'building_id'] = '100'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"28\"').index, 'building_id'] = '34'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"79\"').index, 'building_id'] = '62'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"44\"').index, 'building_id'] = '51'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"125\"').index, 'building_id'] = '69'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"140\"').index, 'building_id'] = '70'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"52\"').index, 'building_id'] = '71'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"100\"').index, 'building_id'] = '72'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"74\"').index, 'building_id'] = '73'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"130\"').index, 'building_id'] = '74'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"10\"').index, 'building_id'] = '35'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"134\"').index, 'building_id'] = '63'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"105\"').index, 'building_id'] = '36'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"69\"').index, 'building_id'] = '37'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"138\"').index, 'building_id'] = '64'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"24\"').index, 'building_id'] = '65'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"6\"').index, 'building_id'] = '66'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"71\"').index, 'building_id'] = '85'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"146\"').index, 'building_id'] = '95'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"98\"').index, 'building_id'] = '96'\n",
    "df_site0_building_metadata.loc[df_site0_building_metadata.query('building_url_code == \"30\"').index, 'building_id'] = '98'\n",
    "\n",
    "# building_id mapped to the scraped labels\n",
    "df_site0_building_metadata['building_id'] = df_site0_building_metadata['building_id'].astype(np.uint16)\n",
    "url_code_building_id_mapping = df_site0_building_metadata.set_index('building_url_code')['building_id'].to_dict()\n",
    "df_site0_labels['building_id'] = df_site0_labels['building_url_code'].map(url_code_building_id_mapping)\n",
    "\n",
    "# Removing unnecessary columns\n",
    "df_site0_building_metadata.drop(columns=['building_name', 'building_link', 'building_type', 'building_url_code'], inplace=True)\n",
    "df_site0_labels.drop(columns=['building_url_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_site0_labels.drop(df_site0_labels.query('meter_reading.isnull()', engine='python').index, inplace=True)\n",
    "\n",
    "df_site0_labels['meter'] = df_site0_labels['meter'].map({'Electric': 0, 'Chilled Water': 1})\n",
    "df_site0_labels['timestamp'] = pd.to_datetime(df_site0_labels['timestamp'], infer_datetime_format=True)\n",
    "df_site0_labels.loc[df_site0_labels.query('meter == 1').index, 'meter_reading'] = df_site0_labels.loc[df_site0_labels.query('meter == 1').index, 'meter_reading'] * 3.51684\n",
    "\n",
    "df_site0_labels.sort_values(by=['timestamp', 'building_id', 'meter'], inplace=True)\n",
    "\n",
    "df_site0 = df_site0.merge(df_site0_labels, on=['timestamp', 'building_id', 'meter'], how='left')    \n",
    "df_building_metadata_external = df_building_metadata.merge(df_site0_building_metadata, on=['building_id', 'square_feet'], how='left')\n",
    "df_site0.rename(columns={'meter_reading_x': 'meter_reading_original', 'meter_reading_y':'meter_reading_scraped'}, inplace=True)\n",
    "\n",
    "del df_site0_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading_original</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meter_reading_scraped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.700012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.700012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>5376</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.700012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>23685</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.700012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>116607</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.700012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter  timestamp  meter_reading_original  site_id primary_use  square_feet  year_built  floor_count  air_temperature  cloud_coverage  dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  wind_speed  meter_reading_scraped\n",
       "0            0      0 2016-01-01                     0.0        0   Education         7432      2008.0          NaN             25.0             6.0             20.0                NaN         1019.700012             0.0         0.0                    0.0\n",
       "1            1      0 2016-01-01                     0.0        0   Education         2720      2004.0          NaN             25.0             6.0             20.0                NaN         1019.700012             0.0         0.0                    0.0\n",
       "2            2      0 2016-01-01                     0.0        0   Education         5376      1991.0          NaN             25.0             6.0             20.0                NaN         1019.700012             0.0         0.0                    0.0\n",
       "3            3      0 2016-01-01                     0.0        0   Education        23685      2002.0          NaN             25.0             6.0             20.0                NaN         1019.700012             0.0         0.0                    0.0\n",
       "4            4      0 2016-01-01                     0.0        0   Education       116607      1975.0          NaN             25.0             6.0             20.0                NaN         1019.700012             0.0         0.0                    0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_site0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 889 ms, total: 1min 9s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "intermed_path = '../../intermed/leak/'\n",
    "\n",
    "df_site0[['building_id', 'meter', 'timestamp', 'meter_reading_original', 'meter_reading_scraped']].to_csv(os.path.join(intermed_path, 'site0.csv.gz'), index=False)\n",
    "df_building_metadata_external.to_csv(os.path.join(intermed_path, 'building_metadata_external.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
