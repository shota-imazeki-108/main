# DSB 反省点諸々まとめ
- 上位スコアの方々の多くに共通していそうな(自分がすべきだったこと)について重点的に触れていきたい。


## Convert to Regressionのpublicとpraivateスコア
- publicのスコアが高く、多くの参加者が流用したと思われる(自分も流用した)。
- publicスコアとprivateスコアの乖離が大きい
- In[18]の処理(trainとtestの平均比較して乖離が大きいものは特徴量から外す、それ以外は平均を合わせる)でtestデータにだけajust_factorでvalueを変えている。
- 完全にelseの処理見落としていた...if直下のところだけ見て「あー、乖離大きいやつは外しているのね、ふーん」って感じでいた(これもいいのか不明)。testだけデータいじるのおかしいやん。決定木系の学習器にいれるわけだし、あかん気がする。
- to_removeを加えない方がスコアいい説のやつは、to_removeではなく、to_excludeも加えてなかったからか？

[対象カーネル](https://www.kaggle.com/braquino/convert-to-regression)

## testデータの一部をtrainデータに含めなかった
- めっちゃ重要そうじゃん(test内のuserの情報を学習できる)。なぜ気づかなかったのか...
- testデータ、installstion_id, timestampで並び替えて、最後から２番目のAssessmentまでをtrainに加えればいいのかな
- 普通にget_dataでできるわ
- get_data、複雑で一応処理の確認とかしたけど、不要そうな特徴量あったし、もっと色々いじったりして、自分の中でしっかりと理解すべきだった。

## Truncate - select one assessment randomly for every child to reflect test set structure
- これはどうなのだ。意味はあるのだろうか。
- installation_idを使わずとも似たような行やら何やらでわかってしまうのか（リークしている的な？）。
- 上手く言葉にできない

## Neural network
- NN系ライブラリ使ったことなさすぎて、脳死で利用していた。本買って勉強するかぁ...
- BN, CNN, RNN, MLP(多層パーセプトロン)

## thresholds
- use threshold Optimizer, not training target distributiion
- threshold Optimizerが不安定だと感じて、500回サンプリングして平均取っている人もいた。
- 提出する際は処理時間短縮でハードコーディングしている。

## Adversarial Validation
- 特徴量削減には使ったけど、ほとんどaucが1で多分自分が実装したやつ間違っている気がするから誰か見て欲しい。
- そういえばサンプリングして不均衡整えたら0.6前後になっていた気がする。確認しよう。

## null importances
- こんなものがあるとは。。。(情弱)
- 読んだけどよくわからん。動かしてみるべしってことか。
- rfとかで適当に学習。その後、目的変数をシャッフルして複数回学習(これで出てくるimportanceがnull importance)
- null impの重要度のヒストグラムのどこにactual impがあるか可視化
- おそらくnull impのヒストグラムに埋もれるか、それより低いactual impはいらないよねって話だと思う。
- 閾値を決めて、選別している。
- 特徴量選択として使えそう。
- 8th placeの人はlocalで試していた(カーネルの処理時間を超過するからだろう)
- 閾値決め打ちで絞るか、スコアいいところ使うか、毎度色々試してみるべきかな

[参照](https://www.kaggle.com/kernels/scriptcontent/4065111/download)

## 特徴量の意味合い
- イベントコードとかをちゃんと見たのだろうか、気になる。
- ratio of good actions / all actions in Activity sessions
- ratio of misclick or misdrag action / count actions (or session duration), count of some specific event codes since the previous Assessment session
- イベントコードとかデータをもっとみるべきだったのかもしれないな
[参考1](https://www.kaggle.com/c/data-science-bowl-2019/discussion/127221)
[参考2](https://www.kaggle.com/zgzjnbzl/visualizing-distraction-and-misclicking)


## 特徴量生成
- Normalized Accuracy feature: (Accuracy - Accuracymeanpertitle) / Featurestdpertitle
    - accuracy features means accuracygroup, ntrueattempts/allattempts, correct/event_num and corret/(correct+false) etc…
- 結構いろんなところでtfidfやw2v使っている。
- We extract features from different parts of the child history data : 1) full history part, 2) last 5/12/48 hour, 3) from last assessment to the current assessment. Since here are some shared devices phenomenon, add different part info may help model.
- Video skip prop ratio : clip event interval / clip length provided by organizer. (Does the child skip the video? If so, when does he skip?)
- 皆、どうやって管理しているのだろうか

## 特徴量選択
- さっきのnull importance
- lightGBMとか事前に回して不要なの削除している。

## random seed averaging
- fold毎にseedを変えている
- ほおお。試してみたい。

## local cv VS public LB
- 早くからLBが不安定なこと(データの少なさと評価指標)に気づいていた
- その時からlocal cvにfocusを当てていた。
- Trust your CVみたいな感じか。LB気にしすぎた...

## 評価指標について
- 1stはqwk不安定だからrmseだけ見ていた
- 無視もありなのね(今回が特殊だからか)。一応、今後の練習がてら自作の評価指標を組み込めるようにはしてみたい。

## 誰かに聞きたい事項まとめ
- [Public vs Private](https://www.kaggle.com/c/data-science-bowl-2019/discussion/127332) で何をしているかわからない
- 特徴量たくさんつくったものの何があるのか把握できていない問題。皆どうやって管理しているんですか。
- パラメータチューニングについてはあまり触れているものがないけど、モデルが複雑化して過学習するから場合によっては不要なこともあるのか

## 反省点まとめ
- 使用しているカーネルの処理を具体的に把握できていなかった。
- testデータの一部をtrainへ加えられる可能性もあるので今後も注意
- データのコード類は面倒でもちゃんと見ようか...
- 全処理を自分で読むなり書いたりして把握できているベースライン的なものを一つ作成する(人のカーネルでも良き)。
- いいスコアのカーネルが上がったら読んでいいところだけそれに加えていく。
- 毎回コピーして自分のを加えていたのはよくないよな...逆をやるべきだったわ。
- 特徴量管理を怠った
- 特徴量大事なんだなぁ。2万個作るってすごい...

## late subで試してみたいこと
- testデータの一部をtrainデータに
- 特徴量生成のところ全部いれる→疲れたから1個だけ笑。
- random seed averaging
- null importance
- threshold Optimizer

- 特徴量作成まとめは作ろう。preprocessor的なもの作りたい。
- イベントコードとかを読んで特徴量へ
- permutation importance

## 試したいけど優先度低めなもの
- bayseのところをoputunaに
- metricに自作関数を入れられるように

## 試したけど再度追加するもの(リファクタリング)
- adversarial validation:実装済み、閾値決めて取得するか、特徴量削除するか

- binary classify
- ensenble(というかxgb, catも試す)
- stucking